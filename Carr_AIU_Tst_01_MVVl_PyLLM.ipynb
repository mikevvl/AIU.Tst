{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMkxx/9Uw903GII69/R/pQT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mikevvl/AIU.Tst/blob/main/Carr_AIU_Tst_01_MVVl_PyLLM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test job 4 Py(LLM) Mike Vl. Vlasov <mikevvl@gmail.com>\n",
        "\n",
        "Base on [УИИ: Вебинар 22 июля. Нейро-методолог](https://colab.research.google.com/drive/1-p4IUICx2jD0Ry3TJ8KqQ-bEW9CK6ecc#scrollTo=MtlkvKqdqr6n)"
      ],
      "metadata": {
        "id": "JIszBqIk5z2x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Установка, импорт библиотек\n",
        "\n",
        "!pip -q install openai==1.35.14\n",
        "\n",
        "import openai\n",
        "from IPython.display import clear_output\n",
        "import textwrap\n",
        "import time\n",
        "import json\n",
        "import os\n",
        "import re\n",
        "import shutil\n",
        "from google.colab import userdata\n",
        "from google.colab.userdata import TimeoutException, SecretNotFoundError, NotebookAccessError\n",
        "import getpass\n",
        "\n"
      ],
      "metadata": {
        "id": "bbNRcVO_zKnP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3fae93d1-3c81-4c63-e8c0-7829d6e7cc97",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m328.5/328.5 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Активация ключа API\n",
        "OPENAI_API_KEY_s = \"OPENAI_API_KEY\"\n",
        "# Установка кодировки вывода по умолчанию на utf-8\n",
        "os.environ[\"PYTHONIOENCODING\"] = \"utf-8\"\n",
        "\n",
        "\n",
        "if OPENAI_API_KEY_s not in os.environ:\n",
        "    try:\n",
        "        # Используем ключ из \"Секретов\" в Колаб: userdata из google.colab\n",
        "        os.environ[OPENAI_API_KEY_s] = userdata.get(OPENAI_API_KEY_s)\n",
        "    except (TimeoutException, SecretNotFoundError, NotebookAccessError) as le_o:\n",
        "        print(f'Не получили из \"Секретов\" в Колаб ключ \"{OPENAI_API_KEY_s}\":\\n--->Error:\"{le_o}\"')\n",
        "        # Функция getpass.getpass() запрашивает ввод пароля или ключа без отображения ввода на экране\n",
        "        openai_key = getpass.getpass(\"Enter Your OpenAI API Key:\")\n",
        "        # Установка ключа API в переменную окружения\n",
        "        os.environ[OPENAI_API_KEY_s] = openai_key\n",
        "\n",
        "# clear_output() # очистка вывода"
      ],
      "metadata": {
        "id": "Te66v2IotwNI",
        "cellView": "form"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Установка типа модели, правил и персонажей для GPT\n",
        "MODEL_s = 'gpt-4o-mini'\n",
        "POS_PERS_s, NEG_PERS_s = \"Бэтмен\", \"Джокер\"\n",
        "SYS_PROMPT_s = f\"\"\"Только отвечаешь на вопросы пользователя.\n",
        "Определяешь вопрос как позитивный или негативный.\n",
        "Если вопрос определяется тобой как позитивный, то ты отвечаешь как {POS_PERS_s}.\n",
        "Если вопрос определяется тобой как негативный, то ты отвечаешь как {NEG_PERS_s}.\n",
        "Ничего не добавляешь от себя.\"\"\".replace('\\n', ' ')\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "WQOPfUVjB6uk"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Функции\n",
        "\n",
        "# Функция для форматирования текста\n",
        "def format_text(text, width=120):\n",
        "    return '\\n'.join(textwrap.fill(line, width) for line in str(text).split('\\n'))\n",
        "\n",
        "\n",
        "# Функция преобразования текста в список строк\n",
        "def text_to_list_lines(text):\n",
        "    lines_list = text.split(\"\\n\") # список по разделителю переноса строки\n",
        "    return [line for line in lines_list if line.strip() != ''] # из списка убираем пустые строки\n",
        "\n",
        "\n",
        "# Функция подсчета количества используемых токенов и стоимость\n",
        "# https://openai.com/pricing\n",
        "# ToDo: parsing https://openai.com/pricing in\n",
        "#  dict[ModelName_s_k: dict[input_price_n_k, output_price_n_k, currency_s_k, req_func_f_k]]\n",
        "#  or Class\n",
        "def tokens_count_and_price(completion, model):\n",
        "    if model == \"gpt-4o\":\n",
        "        # gpt-4o - Input: $5 / 1M tokens - Output: $15 / 1M tokens\n",
        "        input_price, output_price = 5, 15\n",
        "    elif model == \"gpt-4o-mini\":\n",
        "        # gpt-4o-mini - Input: $0.15 / 1M tokens - Output: $0.60 / 1M tokens\n",
        "        input_price, output_price = 0.15, 0.60\n",
        "    else:\n",
        "        # gpt-3.5-turbo-0125 - Input: $0.50 / 1M tokens - Output: $1.50 / 1M tokens\n",
        "        input_price, output_price = 0.5, 1.5\n",
        "    price = input_price * completion.usage.prompt_tokens / 1e6 + \\\n",
        "            output_price * completion.usage.completion_tokens / 1e6\n",
        "    return re.sub(r'\\s+', ' ', f\"\"\"\\nTokens used: {completion.usage.prompt_tokens} +\n",
        "                                                  {completion.usage.completion_tokens} =\n",
        "                                                  {completion.usage.total_tokens}.\n",
        "                                                  *** {model} *** $ {round(price, 5)}\"\"\")\n",
        "\n",
        "\n",
        "# Функция для запроса и получения ответа от OpenAI\n",
        "def get_response_openai(system_prompt,\n",
        "                        user_prompt,\n",
        "                        assistant_prompt='',\n",
        "                        model=MODEL_s,\n",
        "                        temp=0.,\n",
        "                        max_tokens=4096,\n",
        "                        laOtherKwArg_d=None,\n",
        "                        ):\n",
        "    start_time = time.time()\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": system_prompt},\n",
        "        {'role': 'assistant', 'content': assistant_prompt},\n",
        "        {\"role\": \"user\", \"content\": user_prompt}\n",
        "    ]\n",
        "    if laOtherKwArg_d is None: laOtherKwArg_d = {}\n",
        "    response = openai.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=temp,\n",
        "        max_tokens=max_tokens,\n",
        "        **laOtherKwArg_d, # ToDo: checking&|merging the already set arguments above\n",
        "    )\n",
        "    tokens_info = tokens_count_and_price(response, model) # количество используемых токенов и стоимость\n",
        "    execution_time = time.time() - start_time # время выполнения запроса и получения ответа\n",
        "    # Возвращаем ответ OpenAI, время ответа, количество токенов и стоимость\n",
        "    # return response.choices[0].message.content, execution_time, tokens_info\n",
        "    return response, execution_time, tokens_info\n",
        "\n",
        "\n",
        "# Функция диалога (вопрос-ответ) и сохранение\n",
        "def dialog(laPrompt_s: str=\"Задайте вопрос и нажмите Enter (Enter в пустом поле ввода -> Выход):\\n\",\n",
        "           model: str=MODEL_s) -> list:\n",
        "    loQAHist_l = []\n",
        "    while True:\n",
        "        try:\n",
        "            loQ_s = (input(f\"{len(loQAHist_l) +1:02n}. \" + laPrompt_s)).strip()\n",
        "            if loQ_s == '': break\n",
        "            loResp_t = get_response_openai(SYS_PROMPT_s, loQ_s, model=model)\n",
        "            loQAHist_l.append((loQ_s, loResp_t))\n",
        "        except (EOFError, KeyboardInterrupt) as le_o:\n",
        "            # print(le_o)\n",
        "            break\n",
        "\n",
        "    return loQAHist_l\n"
      ],
      "metadata": {
        "id": "MtlkvKqdqr6n",
        "cellView": "form"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Запуск диалога с GPT\n",
        "teR_l = dialog()\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "BICdiLFUHGaD"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Вывод диалога с GPT\n",
        "print(*(f\"Q{_co:02n}: {format_text(_t[0])}\\nA{_co:02n}: {format_text(_t[1].choices[0].message.content)}\\n\"\n",
        "        for _co, _t in enumerate(teR_l, start=1)),\n",
        "     sep='\\n')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "9Zrqf0kYRUqX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ToDo\n",
        "\n",
        "\n",
        "\n",
        "1.   [Попробовать для ввода/вывода Colab: Forms & Jupyter Widgets](https://colab.research.google.com/notebooks/forms.ipynb#scrollTo=62YnDE7i9dqP)\n",
        "2.   Обобщить на другие модели (типы) с помощью LangChain или изменения функции tokens_count_and_price\n",
        "3.   Автоматизировать сбор/актуализацию стоимостных характеристик моделей для функции tokens_count_and_price для ограничения потребления ресурсов ч.изменения в функции dialog\n",
        "\n"
      ],
      "metadata": {
        "id": "HX62y5_pN0LB"
      }
    }
  ]
}